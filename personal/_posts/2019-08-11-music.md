---
layout: post
title: AI Music Generation
description: >

author: author1
noindex: true

---

## Mind band: A Crossmedia AI Music Composing Platform

Various media information in life can have an important impact on our understanding of music. In this paper, we present a demo,Mind Band, which is a Cross-Media artificial intelligent compos- ing platform using our life elements such as emoji, image and humming. In practice, we base our system on the valence-arousal model. We use emotion analysis of life elements to map them to music pieces, which are generated by a Variational Autoencoder- Generative Adversarial Networks model. We provide users with immersive experience by uploading emoji/image/humming and re- trieving emotionally related music pieces back. With this platform, everyone can be a composer.

### User Interface

An app-based interface and a web- based interface are designed. Users can either upload an emoji, an image or a recorded humming, and Mind Band will retrieve the corresponding music piece. The result will be a short video in app-based product or the chat in web-based product.

![image-20191011235556818](/assets/img/music-UI.png)

### Framework

image and emoji are quantified in VA space, humming converted to MIDI to direct generation of music, and musical pieces generated by VAE/GAN model are retrieved based on VA index

![image-20191011235625669](/assets/img/music-framework.png)

### Music sample

<iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/664526867&color=%23617cae&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe>
<iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/664526747&color=%23617cae&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe>
<iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/664523786&color=%23617cae&auto_play=false&hide_related=false&show_comments=true&show_user=true&show_reposts=false&show_teaser=true"></iframe>
### Conclusion

Based on the Valence-Arousal space criteria, our demo combines several techniques to convert information from one media to an- other, to enable users to enjoy music creation without superb music knowledge. There is still a lot of future work to do. Firstly, a user study can be conducted to better design customized user interface. Secondly, other forms of media can also be involved for music generation. Thirdly, it is possible to hybrid the process of VA evalu- ation and music generation to form conditional generative model to generate music upon every query.

Want to try the system by yourself? Coming soon...

[docs]: ../../docs/README.md

